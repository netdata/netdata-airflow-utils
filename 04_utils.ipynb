{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Do Stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def dest(destination_dataset_table, prefix_dataset='tmp', return_dataset_only=False, return_table_only=False):\n",
    "    \"\"\"If AIRFLOW_ENV != PROD then write results to `prefix_dataset` instead.\n",
    "\n",
    "    :param destination_dataset_table: destination to write results to.\n",
    "    :return: destination_dataset_table: destination to write results to with prefix added if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    AIRFLOW_ENV = os.environ.get(\"AIRFLOW_ENV\", \"UNK\")\n",
    "\n",
    "    if AIRFLOW_ENV != 'PROD':\n",
    "        destination_dataset_table_list = destination_dataset_table.replace(':', '.').split('.')\n",
    "        destination_project = destination_dataset_table_list[0]\n",
    "        destination_dataset = prefix_dataset\n",
    "        destination_table = f'{destination_dataset_table_list[1]}_{destination_dataset_table_list[2]}'\n",
    "        destination_dataset_table = f'{destination_project}.{destination_dataset}.{destination_table}'\n",
    "\n",
    "    destination_parts = destination_dataset_table.split('.')\n",
    "\n",
    "    if return_dataset_only == True:\n",
    "        return destination_parts[1]\n",
    "    elif return_table_only == True:\n",
    "        return destination_parts[2]\n",
    "    else:\n",
    "        return destination_dataset_table\n",
    "\n",
    "\n",
    "def dest_dict(destination_dataset_table, prefix_dataset='tmp'):\n",
    "    \"\"\"Wrapper for `dest()` but to return as dict.\n",
    "    \"\"\"\n",
    "    destination_dataset_table = dest(destination_dataset_table, prefix_dataset)\n",
    "    destination_parts = destination_dataset_table.split('.')\n",
    "    return {\n",
    "        \"projectId\": destination_parts[0],\n",
    "        \"datasetId\": destination_parts[1],\n",
    "        \"tableId\": destination_parts[2]\n",
    "    }\n",
    "\n",
    "\n",
    "def sched(schedule):\n",
    "    \"\"\"If AIRFLOW_ENV != PROD then schedule should be `@once`.\n",
    "\n",
    "    :param schedule: schedule for prod.\n",
    "    :return: schedule: `schedule` if prod else `@once`.\n",
    "    \"\"\"\n",
    "\n",
    "    AIRFLOW_ENV = os.environ.get(\"AIRFLOW_ENV\", \"UNK\")\n",
    "\n",
    "    if AIRFLOW_ENV == 'PROD':\n",
    "        return schedule\n",
    "    else:\n",
    "        return '@once'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "assert sched('foo') == '@once'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fedf5a0bda284b600ce5cf8d11661c8aa181286e797d7b6aa742a7f5fed6b99f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('netdata-airflow-utils--F3buUxQ': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
