{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> General purpose utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "from typing import Dict, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def dest(destination_dataset_table, prefix_dataset='tmp', return_dataset_only=False, return_table_only=False) -> Dict[str, Any]:\n",
    "    \"\"\"If `AIRFLOW_ENV != PROD` then write results to `prefix_dataset` instead.\n",
    "\n",
    "    :param destination_dataset_table: destination to write results to.\n",
    "    :return: destination_dataset_table: destination to write results to with prefix added if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    AIRFLOW_ENV = os.environ.get(\"AIRFLOW_ENV\", \"UNK\")\n",
    "\n",
    "    if AIRFLOW_ENV != 'PROD':\n",
    "        destination_dataset_table_list = destination_dataset_table.replace(':', '.').split('.')\n",
    "        destination_project = destination_dataset_table_list[0]\n",
    "        destination_dataset = prefix_dataset\n",
    "        destination_table = f'{destination_dataset_table_list[1]}_{destination_dataset_table_list[2]}'\n",
    "        destination_dataset_table = f'{destination_project}.{destination_dataset}.{destination_table}'\n",
    "\n",
    "    destination_parts = destination_dataset_table.split('.')\n",
    "\n",
    "    if return_dataset_only == True:\n",
    "        return destination_parts[1]\n",
    "    elif return_table_only == True:\n",
    "        return destination_parts[2]\n",
    "    else:\n",
    "        return destination_dataset_table\n",
    "\n",
    "\n",
    "def dest_dict(destination_dataset_table, prefix_dataset='tmp') -> Dict[str, str]:\n",
    "    \"\"\"Wrapper for `dest()` but to return as dict.\n",
    "    \"\"\"\n",
    "    destination_dataset_table = dest(destination_dataset_table, prefix_dataset)\n",
    "    destination_parts = destination_dataset_table.split('.')\n",
    "    return {\n",
    "        \"projectId\": destination_parts[0],\n",
    "        \"datasetId\": destination_parts[1],\n",
    "        \"tableId\": destination_parts[2]\n",
    "    }\n",
    "\n",
    "\n",
    "def sched(schedule: Any) -> Any:\n",
    "    \"\"\"If AIRFLOW_ENV != PROD then schedule should be `@once`.\n",
    "\n",
    "    :param schedule: schedule for prod.\n",
    "    :return: schedule: `schedule` if prod else `@once`.\n",
    "    \"\"\"\n",
    "\n",
    "    AIRFLOW_ENV = os.environ.get(\"AIRFLOW_ENV\", \"UNK\")\n",
    "\n",
    "    if AIRFLOW_ENV == 'PROD':\n",
    "        return schedule\n",
    "    else:\n",
    "        return '@once'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "#hide\n",
    "os.environ.pop('AIRFLOW_ENV', None)\n",
    "assert sched('foo') == '@once'\n",
    "os.environ['AIRFLOW_ENV'] = 'PROD'\n",
    "assert sched('foo') == 'foo'\n",
    "\n",
    "assert dest_dict('p.d.t', prefix_dataset='') == {'projectId': 'p', 'datasetId': 'd', 'tableId': 't'}\n",
    "\n",
    "os.environ.pop('AIRFLOW_ENV', None)\n",
    "assert dest('p.d.t') == 'p.tmp.d_t'\n",
    "assert dest('p.d.t', return_dataset_only=True) == 'tmp'\n",
    "assert dest('p.d.t', return_table_only=True) == 'd_t'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
